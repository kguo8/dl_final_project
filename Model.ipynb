{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels=[3, 40, 60, 120, 160, 240], kernel=5, padding=2, pool_kernel=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels[0], channels[1], kernel, padding=padding)\n",
    "        self.conv2 = nn.Conv2d(channels[1], channels[2], kernel, padding=padding)\n",
    "        self.conv3 = nn.Conv2d(channels[2], channels[3], kernel, padding=padding)\n",
    "        self.conv4 = nn.Conv2d(channels[3], channels[4], kernel, padding=padding)\n",
    "        self.conv5 = nn.Conv2d(channels[4], channels[5], kernel, padding=padding)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        # setting stride to equal kernel\n",
    "        self.pool = nn.MaxPool2d(pool_kernel, stride=pool_kernel)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv2(self.relu(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.conv4(self.relu(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        return self.relu(self.conv5(x))\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels=[240, 120, 60, 2, 1], kernel=5, padding=2, mid_kernel=2):\n",
    "        super().__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(channels[0], channels[1], kernel, padding=padding)\n",
    "        # kernel and stride to match the pool layer in the encoder\n",
    "        self.deconv2 = nn.ConvTranspose2d(channels[1], channels[2], mid_kernel, stride=mid_kernel)\n",
    "        self.deconv3 = nn.ConvTranspose2d(channels[2], channels[3], mid_kernel, stride=mid_kernel)\n",
    "        # for generating output (out channel is 1 mask is one layer)\n",
    "        self.deconv4 = nn.ConvTranspose2d(channels[3], channels[4], kernel, padding=padding)\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.deconv1(x))\n",
    "        x = self.relu(self.deconv2(x))\n",
    "        return self.deconv4(self.deconv3(x)).squeeze()\n",
    "\n",
    "class WickUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.augmentations.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_names, transform, img_size=False):\n",
    "        self.image_names = image_names\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(f'prima/{self.image_names[idx]}.tif')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        mask = scipy.sparse.load_npz(f'prima/mask_{self.image_names[idx]}.npz').todense()\n",
    "        \n",
    "        transformed = self.transform(image=img, mask=mask)\n",
    "        \n",
    "        if self.img_size:\n",
    "            return transformed[\"image\"], transformed[\"mask\"], img.shape[:2]\n",
    "        return transformed[\"image\"], transformed[\"mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# was randomly chosen\n",
    "training_files = {'00008152', '00008153', '00008150', '00008148', '00325453',\n",
    "'00008063', '00008230', '00322470', '00325454', '00008332',\n",
    "'00008062', '00008143', '00008344', '00008141', '00008146',\n",
    "'00008088', '00008346', '00325450', '00008149', '00008147',\n",
    "'00325448', '00008227', '00008151', '00322599', '00322596',\n",
    "'00008334', '00008336', '00008089', '00008229', '00322468',\n",
    "'00008144', '00008340', '00008061', '00008084', '00325449',\n",
    "'00322471', '00008140', '00322469', '00008086', '00008145'}\n",
    "\n",
    "test_files = {'00008228',\n",
    " '00322597',\n",
    " '00008338',\n",
    " '00008064',\n",
    " '00322598',\n",
    " '00325451',\n",
    " '00008142',\n",
    " '00325452',\n",
    " '00008154',\n",
    " '00008342'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_fun, optimizer):\n",
    "    total_loss = 0\n",
    "    total_row = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for img, mask in dataloader:\n",
    "#         img = img.cuda()\n",
    "#         mask = mask.cuda()\n",
    "        \n",
    "        pred = model(img)\n",
    "        loss = loss_fun(pred, mask.float())\n",
    "\n",
    "        total_loss += loss.item() * img.shape[0]\n",
    "        total_row += img.shape[0]\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / total_row\n",
    "\n",
    "def validate(model, dataloader, loss_fun):\n",
    "    total_loss = 0\n",
    "    total_row = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, mask in dataloader:\n",
    "#             img = img.cuda()\n",
    "#             mask = mask.cuda()\n",
    "\n",
    "            pred = model(img)\n",
    "            loss = loss_fun(pred, mask.float())\n",
    "\n",
    "            total_loss += loss.item() * img.shape[0]\n",
    "            total_row += img.shape[0]\n",
    "\n",
    "    return total_loss / total_row\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        \n",
    "        A.PadIfNeeded(min_height=10296, min_width=7020),\n",
    "        A.Resize(396, 264),\n",
    "        ### add here\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "         A.PadIfNeeded(min_height=10296, min_width=7020),\n",
    "         A.Resize(396, 264),\n",
    "         A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "         ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(511)\n",
    "train_files = np.random.choice(list(training_files), 35, replace=False).tolist()\n",
    "val_files = list(training_files.difference(train_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = {}\n",
    "validation_loss = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WickUnet()\n",
    "#  model.cuda()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_ds = ImageDataset(train_files, train_transform)\n",
    "val_ds = ImageDataset(val_files, val_transform)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "for t in range(epoch):\n",
    "    start = time.time()\n",
    "    tl = train(model, train_dl, loss_fun, optimizer)\n",
    "    train_time = format_time(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    vl = validate(model, train_dl, loss_fun)\n",
    "    val_time = format_time(time.time() - start)\n",
    "\n",
    "    train_loss[t] = tl\n",
    "    validation_loss[t] = vl\n",
    "\n",
    "    print(f'Epoch: {t}, train_loss: {round(tl, 4)}, train_time: {train_time}, val_loss: {round(vl, 4)}, val_time: {val_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss.keys(), train_loss.values(), label='train')\n",
    "plt.plot(validation_loss.keys(), validation_loss.values(), val='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
